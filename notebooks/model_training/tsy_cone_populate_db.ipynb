{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4753bf2-0c13-492f-afae-f28616da8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data source for sandbox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/23 20:26:25 INFO mlflow.tracking.fluent: Experiment with name 'IR Cone Fit betaExperiment4' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≠Ô∏è  Skipping 2025-06-22: no exact curve_date in pivot\n",
      "using model: EmpCov_1yrFit\n",
      "using model: EmpCov_1yrFit\n",
      "using model: EmpCov_1yrFit\n",
      "‚è≠Ô∏è  Skipping 2025-06-21: no exact curve_date in pivot\n",
      "‚è≠Ô∏è  Skipping 2025-06-19: no exact curve_date in pivot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'EmpCov_1yrFit' already exists. Creating a new version of this model...\n",
      "Registered model 'EmpCov_1yrFit' already exists. Creating a new version of this model...\n",
      "Registered model 'EmpCov_1yrFit' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run IR_2025-06-18 at: http://127.0.0.1:8768/#/experiments/1552/runs/b6a5c085e7ec4834b49608bd136ab6bd\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "üèÉ View run IR_2025-06-20 at: http://127.0.0.1:8768/#/experiments/1552/runs/5e479809774b463cbcea65dcc3e6a565\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "üèÉ View run IR_2025-06-23 at: http://127.0.0.1:8768/#/experiments/1552/runs/e186c59c3973421c94a184c10d291769\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "‚ö†Ô∏è  3 errors:\n",
      "  ‚Ä¢ 2025-06-18: PERMISSION_DENIED: project fsi-market-data (68279e5fabff3841a2719110) data cannot be modified from project quantitative-development (685980acb0c3316ebeb21d19)\n",
      "  ‚Ä¢ 2025-06-20: PERMISSION_DENIED: project fsi-market-data (68279e5fabff3841a2719110) data cannot be modified from project quantitative-development (685980acb0c3316ebeb21d19)\n",
      "  ‚Ä¢ 2025-06-23: PERMISSION_DENIED: project fsi-market-data (68279e5fabff3841a2719110) data cannot be modified from project quantitative-development (685980acb0c3316ebeb21d19)\n",
      "üèÉ View run populate_ir_cones_2025-06-23 at: http://127.0.0.1:8768/#/experiments/1552/runs/11d5c84d1758445daaae7b268b0759ba\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "‚è≠Ô∏è  Skipping 2025-06-22: no exact curve_date in pivot\n",
      "using model: EmpCov_5yrFit\n",
      "using model: EmpCov_5yrFit\n",
      "using model: EmpCov_5yrFit\n",
      "‚è≠Ô∏è  Skipping 2025-06-19: no exact curve_date in pivot\n",
      "‚è≠Ô∏è  Skipping 2025-06-21: no exact curve_date in pivot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'EmpCov_5yrFit' already exists. Creating a new version of this model...\n",
      "Registered model 'EmpCov_5yrFit' already exists. Creating a new version of this model...\n",
      "Registered model 'EmpCov_5yrFit' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run IR_2025-06-18 at: http://127.0.0.1:8768/#/experiments/1552/runs/b246f8bd89af4d8fbf6e361bc923721e\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "üèÉ View run IR_2025-06-20 at: http://127.0.0.1:8768/#/experiments/1552/runs/1a19fd2fcfe249a69b8f6132a0253f2b\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "üèÉ View run IR_2025-06-23 at: http://127.0.0.1:8768/#/experiments/1552/runs/4056514af80543caa4504b937c85aefc\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n",
      "‚ö†Ô∏è  3 errors:\n",
      "  ‚Ä¢ 2025-06-18: PERMISSION_DENIED: project fsi-market-data (68279e5fabff3841a2719110) data cannot be modified from project quantitative-development (685980acb0c3316ebeb21d19)\n",
      "  ‚Ä¢ 2025-06-20: PERMISSION_DENIED: project fsi-market-data (68279e5fabff3841a2719110) data cannot be modified from project quantitative-development (685980acb0c3316ebeb21d19)\n",
      "  ‚Ä¢ 2025-06-23: PERMISSION_DENIED: project fsi-market-data (68279e5fabff3841a2719110) data cannot be modified from project quantitative-development (685980acb0c3316ebeb21d19)\n",
      "üèÉ View run populate_ir_cones_2025-06-23 at: http://127.0.0.1:8768/#/experiments/1552/runs/7215a853859e4eba846eb78fb24e55b9\n",
      "üß™ View experiment at: http://127.0.0.1:8768/#/experiments/1552\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.sklearn\n",
    "\n",
    "from data.data_source import get_data_source\n",
    "from data.treasury_curve import get_yield_curve\n",
    "from models.covariance.empirical_covariance import EmpiricalCovarianceModel as model_choice\n",
    "from config import env\n",
    "from utils.artifact_saver import get_artifact_path\n",
    "import math\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CURVE_TYPE        = \"US Treasury Par\"\n",
    "TENORS            = [1/12, 0.125, 2/12, 0.25, 4/12, 0.5, 1, 2, 3, 5, 7, 10, 20, 30]\n",
    "N_SIMS            = 1000\n",
    "MLFLOW_EXPERIMENT = \"IR Cone Fit betaExperiment4\"\n",
    "backfill_DAYS     = 5       # how many days back to pull data\n",
    "MAX_WORKERS       = 12\n",
    "ds                = get_data_source()\n",
    "model_class = model_choice\n",
    "model_shortname = model_class.name\n",
    "\n",
    "\n",
    "def format_tenor(x):\n",
    "    total_months = round(x * 12 * 2) / 2\n",
    "    years = int(total_months // 12)\n",
    "    months = total_months - years * 12\n",
    "    parts = []\n",
    "    if years:\n",
    "        parts.append(f\"{years}Y\")\n",
    "    if months:\n",
    "        parts.append(f\"{months:.1f}M\" if not months.is_integer() else f\"{int(months)}M\")\n",
    "    return \"\".join(parts) or \"0M\"\n",
    "\n",
    "\n",
    "def batch_insert_rate_cones(records, batch_size=200):\n",
    "    total = 0\n",
    "    for i in range(0, len(records), batch_size):\n",
    "        batch = records[i : i + batch_size]\n",
    "        vals = \",\\n\".join(\n",
    "            f\"('{r['curve_type']}', {r['days_forward']:.1f}, '{r['curve_date']}', \"\n",
    "            f\"'{r['cone_type']}', '{r['tenor_str']}', {r['rate']:.8f}, {r['tenor_num']:.8f}, '{r['model_type']}')\"\n",
    "            for r in batch\n",
    "        )        \n",
    "        sql = f\"\"\"\n",
    "        INSERT INTO rate_cones\n",
    "          (curve_type, days_forward, curve_date, cone_type, tenor_str, rate, tenor_num, model_type)\n",
    "        VALUES {vals}\n",
    "        ON CONFLICT DO NOTHING;\n",
    "        \"\"\"\n",
    "        ds.query(sql)\n",
    "        total += len(batch)\n",
    "    return total\n",
    "\n",
    "\n",
    "def plot_ir_cones_matplotlib(base_curve: pd.Series, ir_cone_df: pd.DataFrame, days_forward: int, title: str = \"\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sample_ids = np.random.choice(\n",
    "        ir_cone_df[\"sim_id\"].unique(),\n",
    "        size=min(100, ir_cone_df[\"sim_id\"].nunique()),\n",
    "        replace=False\n",
    "    )\n",
    "    for sim_id in sample_ids:\n",
    "        sim = ir_cone_df[ir_cone_df[\"sim_id\"] == sim_id]\n",
    "        plt.plot(sim[\"tenor_num\"], sim[\"rate_simulated\"], color=\"gray\", alpha=0.1)\n",
    "\n",
    "    plt.plot(base_curve.index, base_curve.values,\n",
    "             color=\"crimson\", linewidth=2.5, label=\"Base Curve\")\n",
    "    plt.xlabel(\"Tenor (years)\")\n",
    "    plt.ylabel(\"Yield (%)\")\n",
    "    plt.title(title or f\"{days_forward}-Day IR Cones ({N_SIMS} sims) on {base_curve.name}\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fn = get_artifact_path(f\"tsy_cones_{base_curve.name}_{days_forward}d.png\")\n",
    "    plt.savefig(fn, dpi=150)\n",
    "    plt.close()\n",
    "    return fn\n",
    "\n",
    "\n",
    "def generate_ir_cone(base_curve: pd.Series,\n",
    "                     cov_model: model_class,\n",
    "                     n_sims: int,\n",
    "                     days_forward: int) -> pd.DataFrame:\n",
    "\n",
    "    N = len(base_curve)\n",
    "    \n",
    "    cov = cov_model.covariance_ * days_forward\n",
    "    \n",
    "    drift = getattr(cov_model, \"drift_\", np.zeros(N))\n",
    "    drift_fw = drift * days_forward  # horizon drift    \n",
    "\n",
    "    rand_deltas = np.random.multivariate_normal(\n",
    "        mean=np.zeros(len(base_curve)),\n",
    "        cov=cov,\n",
    "        size=n_sims\n",
    "    )\n",
    "    \n",
    "    base_vals = base_curve.to_numpy()\n",
    "    sims = base_vals[np.newaxis, :] + drift_fw[np.newaxis, :] + rand_deltas\n",
    "\n",
    "    records = [\n",
    "        {\"sim_id\": sim, \"tenor_num\": base_curve.index[i], \"rate_simulated\": sims[sim, i]}\n",
    "        for sim in range(n_sims)\n",
    "        for i in range(len(base_curve))\n",
    "    ]\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "def populate_ir_cones(backfill_days: int,\n",
    "                      fit_window_years: int = 1,\n",
    "                      years_back: int = 0,\n",
    "                      max_workers: int = 4):\n",
    "    end_date   = datetime.today().date()\n",
    "    start_date = max(\n",
    "        end_date - relativedelta(days=backfill_days, years=years_back),\n",
    "        datetime(2010, 1, 1).date()\n",
    "    )\n",
    "    all_dates = pd.date_range(start=start_date, end=end_date, freq=\"D\").date\n",
    "\n",
    "    mlflow.set_experiment(MLFLOW_EXPERIMENT)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"populate_ir_cones_{end_date}\") as parent:\n",
    "        parent_id = parent.info.run_id\n",
    "        mlflow.log_params({\n",
    "            \"as_of_date\": str(start_date),\n",
    "            \"backfill_days\": backfill_days,\n",
    "            \"fit_window_years\": fit_window_years,\n",
    "            \"curve_type\": CURVE_TYPE,\n",
    "            \"n_sims\": N_SIMS,\n",
    "        })\n",
    "\n",
    "        total_obs, total_vars, trace_covs, errors = [], [], [], []\n",
    "\n",
    "        def task(asof_date):\n",
    "            try:\n",
    "                window_start = asof_date - relativedelta(years=fit_window_years)\n",
    "                window_start = max(window_start, datetime(2010,1,1).date())\n",
    "\n",
    "                sql = f\"\"\"\n",
    "                SELECT curve_date, tenor_num, rate\n",
    "                  FROM rate_curves\n",
    "                 WHERE curve_type = '{CURVE_TYPE}'\n",
    "                   AND curve_date BETWEEN '{window_start}' AND '{asof_date}'\n",
    "                   AND tenor_num    IN ({', '.join(map(str, TENORS))})\n",
    "                 ORDER BY curve_date DESC, tenor_num;\n",
    "                \"\"\"\n",
    "                df = ds.query(sql).to_pandas()\n",
    "                if df.empty:\n",
    "                    return (asof_date, \"No curve data\")\n",
    "\n",
    "                pivot = (\n",
    "                    df.pivot(index=\"curve_date\", columns=\"tenor_num\", values=\"rate\")\n",
    "                      .sort_index()\n",
    "                      .interpolate(method=\"linear\", axis=0)\n",
    "                      .dropna()\n",
    "                )\n",
    "                if asof_date not in pivot.index:\n",
    "                    print(f\"‚è≠Ô∏è  Skipping {asof_date}: no exact curve_date in pivot\")\n",
    "                    return None\n",
    "\n",
    "                asof_actual = (asof_date if asof_date in pivot.index\n",
    "                               else pivot.index[pivot.index <= asof_date].max())\n",
    "                base_curve = pivot.loc[asof_date]\n",
    "                deltas     = pivot.diff().dropna()   # these deltas now span your lookback window\n",
    "\n",
    "                model_name = f'{model_shortname}_{fit_window_years}yrFit'\n",
    "                print('using model: ' + model_name)\n",
    "\n",
    "                for days_forward in (30, 90):\n",
    "                    model   = model_class().fit(deltas.values)\n",
    "                    cone_df = generate_ir_cone(base_curve, model, N_SIMS, days_forward)\n",
    "                    chart   = plot_ir_cones_matplotlib(base_curve, cone_df,\n",
    "                                                       days_forward,\n",
    "                                                       title=f\"{days_forward}-day cones\")\n",
    "    \n",
    "                    pctls = [1,5,10,50,90,95,99]\n",
    "                    pct_df = (\n",
    "                        cone_df.groupby(\"tenor_num\")[\"rate_simulated\"]\n",
    "                               .quantile([p/100 for p in pctls])\n",
    "                               .unstack(level=1)\n",
    "                               .reset_index()\n",
    "                               .melt(id_vars=\"tenor_num\", var_name=\"percentile\", value_name=\"rate\")\n",
    "                    )\n",
    "                    pct_df[\"percentile\"] = pct_df[\"percentile\"].astype(float)\n",
    "    \n",
    "                    pct_df[\"curve_type\"]   = CURVE_TYPE\n",
    "                    pct_df[\"tenor_str\"]    = pct_df[\"tenor_num\"].apply(format_tenor)\n",
    "                    pct_df[\"cone_type\"]    = pct_df[\"percentile\"].apply(lambda p: f\"{int(p*100)}%\")\n",
    "                    pct_df[\"curve_date\"]   = asof_date\n",
    "                    pct_df[\"days_forward\"] = days_forward\n",
    "                    pct_df[\"model_type\"] = model_name\n",
    "    \n",
    "                    recs = pct_df[[\n",
    "                        \"curve_type\",\"days_forward\",\"curve_date\",\n",
    "                        \"cone_type\",\"tenor_str\",\"rate\",\"tenor_num\", \"model_type\"\n",
    "                    ]].to_dict(orient=\"records\")\n",
    "                    inserted = batch_insert_rate_cones(recs)\n",
    "    \n",
    "                    n_obs     = len(deltas)\n",
    "                    total_var = float(np.var(deltas.values))\n",
    "                    trace_cv  = float(np.trace(model.covariance_))\n",
    "    \n",
    "                    total_obs.append(n_obs)\n",
    "                    total_vars.append(total_var)\n",
    "                    trace_covs.append(trace_cv)\n",
    "                \n",
    "                    input_example = deltas.values[:1]\n",
    "    \n",
    "                    with mlflow.start_run(\n",
    "                        run_name=f\"IR_{asof_date}\",\n",
    "                        nested=True,\n",
    "                        tags={\"mlflow.parentRunId\": parent_id}\n",
    "                    ):\n",
    "                        mlflow.log_params({\n",
    "                            \"as_of_date\": str(asof_actual),\n",
    "                            \"backfill_days\": backfill_days,\n",
    "                            \"fit_window_years\": fit_window_years,\n",
    "                            \"curve_type\": CURVE_TYPE,\n",
    "                            \"n_sims\": N_SIMS,\n",
    "                        })\n",
    "                        mlflow.log_metrics({\n",
    "                            \"n_obs\": n_obs,\n",
    "                            \"total_var\": total_var,\n",
    "                            \"trace_cov\": trace_cv,\n",
    "                            \"days_forward\": days_forward,\n",
    "                            \"dates_processed\": 1,\n",
    "                        })\n",
    "                        mlflow.sklearn.log_model(\n",
    "                            sk_model=model,\n",
    "                            artifact_path=\"model\",\n",
    "                            registered_model_name=model_name,\n",
    "                            input_example=input_example\n",
    "                        )\n",
    "                        mlflow.log_artifact(chart, artifact_path=\"charts\")\n",
    "    \n",
    "                return None\n",
    "\n",
    "            except Exception as e:\n",
    "                return (asof_date, str(e))\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as exe:\n",
    "            futures = [exe.submit(task, d) for d in all_dates]\n",
    "            for fut in as_completed(futures):\n",
    "                if err := fut.result():\n",
    "                    errors.append(err)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"dates_processed\": len(all_dates) - len(errors),\n",
    "            \"n_errors\": len(errors),\n",
    "            \"n_obs\": sum(total_obs),\n",
    "            \"total_var\": float(np.mean(total_vars)) if total_vars else 0.0,\n",
    "            \"trace_cov\": float(np.mean(trace_covs)) if trace_covs else 0.0,\n",
    "        })\n",
    "\n",
    "        if errors:\n",
    "            print(f\"‚ö†Ô∏è  {len(errors)} errors:\")\n",
    "            for d, msg in errors:\n",
    "                print(f\"  ‚Ä¢ {d}: {msg}\")\n",
    "        else:\n",
    "            print(\"‚úÖ All cones processed and logged.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "\n",
    "    populate_ir_cones(\n",
    "        backfill_days=backfill_DAYS,\n",
    "        fit_window_years=1,\n",
    "        max_workers=MAX_WORKERS,\n",
    "        years_back=0\n",
    "    )\n",
    "    \n",
    "    populate_ir_cones(\n",
    "        backfill_days=backfill_DAYS,\n",
    "        fit_window_years=5,\n",
    "        max_workers=MAX_WORKERS,\n",
    "        years_back=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01786df-5316-4664-8cac-cd80cd1f45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "https://se-demo.domino.tech/workspace-session/nick_goble/quantitative-development?\n",
    "owner=nick_goble&projectName=quantitative-development&runId=68598528b0c3316ebeb21d38&workspaceId=68598528b0c3316ebeb21d36"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
